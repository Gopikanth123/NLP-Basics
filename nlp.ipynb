{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc9PGjAtS0hl",
        "outputId": "f00471f4-ffed-400f-bea6-41c1f53fd6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "3OQfB6UbUf6-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(nlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzz-ngfYU4HX",
        "outputId": "25ea28fe-ed4d-4296-f30e-83e2b71e81e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.lang.en.English"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('Apple is looking at buying U.K. startup for $6 millions.')\n",
        "for token in doc:\n",
        "  print(token.text,token.pos_,token.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykaU2iZnU6jy",
        "outputId": "75bd2609-290f-4cbb-f04a-e34393a31c80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple PROPN nsubj\n",
            "is AUX aux\n",
            "looking VERB ROOT\n",
            "at ADP prep\n",
            "buying VERB pcomp\n",
            "U.K. PROPN dobj\n",
            "startup NOUN dobj\n",
            "for ADP prep\n",
            "$ SYM quantmod\n",
            "6 NUM nummod\n",
            "millions NOUN pobj\n",
            ". PUNCT punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain('dobj')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sVf4oIGkXTCs",
        "outputId": "358f90d4-8926-4f54-fba3-1910cf18bffb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'direct object'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain('nsubj')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5AsYKzA6X81m",
        "outputId": "8821ba70-c0d0-4196-96e2-0fbc88b2c62c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nominal subject'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhByIa0_YDGW",
        "outputId": "9832056a-599a-407e-c7bc-f019e985055c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Apple is looking at buying U.K. startup for $6 millions."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo4hzSJtYHjo",
        "outputId": "8b05ad4a-3bdf-447d-9403-beeea8f739a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[6].pos_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "f7aQKj0gYKhb",
        "outputId": "82108a03-517f-4b8c-e0e5-1288fb9b8ff7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NOUN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[6].dep_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GOPYTP0BYRVZ",
        "outputId": "0ec42948-2a49-4693-dd87-4cc5f01e3d8e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dobj'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain('dobj')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "L9IjQnlfYToQ",
        "outputId": "1bc675a2-f9a1-4f30-a223-8e4abdadeaf8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'direct object'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s='i am sending mail to the gopikanthtirumani@gmail.com'\n",
        "d=nlp(s)\n",
        "for i in d:\n",
        "  print(i.text,i.pos_,i.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeChHAhEYYza",
        "outputId": "5059950e-3e46-4d5f-db3f-a445052dcc06"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i PRON nsubj\n",
            "am AUX aux\n",
            "sending VERB ROOT\n",
            "mail NOUN dobj\n",
            "to ADP dative\n",
            "the DET det\n",
            "gopikanthtirumani@gmail.com NOUN pobj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Named entities in the spaCy module are words or phrases that represent specific types of objects, such as people, places, organizations, products, and dates.\n",
        "\n",
        "# SpaCy uses a statistical model to identify and classify named entities in text. The model is trained on a large corpus of text data and uses various features such as part-of-speech tags, dependency parsing, and word embeddings to identify entities.\n",
        "\n",
        "# Once identified, spaCy assigns a label to each entity based on its type, such as PERSON for people, GPE (Geopolitical Entity) for countries or cities, ORG for organizations, and DATE for dates.\n",
        "\n",
        "# Named entity recognition (NER) is a useful tool for various natural language processing tasks, such as information extraction, sentiment analysis, and question answering."
      ],
      "metadata": {
        "id": "w-4tEDileyM9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('Apple is looking at buying a U.K startup for $6 billions')\n",
        "for ent in doc.ents:\n",
        "  print(ent.text+\" - \" +ent.label_+\" - \"+str(spacy.explain(ent.label_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lKnN_dqcG9Y",
        "outputId": "655178d7-9453-40c7-be37-130ef011dee6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple - ORG - Companies, agencies, institutions, etc.\n",
            "U.K - ORG - Companies, agencies, institutions, etc.\n",
            "$6 billions - MONEY - Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc,style='ent',jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "G2Vpb3rvfV5t",
        "outputId": "23f94e7c-4e24-40db-f636-bab9ebd3ca15"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is looking at buying a \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U.K\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " startup for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $6 billions\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1=nlp(\"Apple is planning to release a new iPhone next month. Elon Musk, the CEO of Tesla, announced that they will build a new factory in Germany. The United Nations held a summit to discuss climate change and sustainable development. Shakespeare was born in Stratford-upon-Avon on April 23, 1564. Harry Potter and the Philosopher's Stone is a novel written by J.K. Rowling.\")\n",
        "for ent in doc1.ents:\n",
        "  print(ent.text+\" - \" +ent.label_+\" - \"+str(spacy.explain(ent.label_)))"
      ],
      "metadata": {
        "id": "EBWQauTQfuqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077a1653-3395-4695-a0cb-47fe714bf8b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple - ORG - Companies, agencies, institutions, etc.\n",
            "iPhone - ORG - Companies, agencies, institutions, etc.\n",
            "next month - DATE - Absolute or relative dates or periods\n",
            "Elon Musk - PERSON - People, including fictional\n",
            "Tesla - ORG - Companies, agencies, institutions, etc.\n",
            "Germany - GPE - Countries, cities, states\n",
            "The United Nations - ORG - Companies, agencies, institutions, etc.\n",
            "Shakespeare - PERSON - People, including fictional\n",
            "Stratford - ORG - Companies, agencies, institutions, etc.\n",
            "April 23, 1564 - DATE - Absolute or relative dates or periods\n",
            "Harry Potter - PERSON - People, including fictional\n",
            "the Philosopher's Stone - ORG - Companies, agencies, institutions, etc.\n",
            "J.K. Rowling - PERSON - People, including fictional\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc1,style='ent',jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "mZ0fG1jsgaOP",
        "outputId": "a57212ee-5efc-4acb-a2e1-d9beb9887d9a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is planning to release a new \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    iPhone\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    next month\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Elon Musk\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", the CEO of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tesla\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", announced that they will build a new factory in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Germany\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    The United Nations\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " held a summit to discuss climate change and sustainable development. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Shakespeare\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " was born in \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Stratford\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "-upon-Avon on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    April 23, 1564\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Harry Potter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the Philosopher's Stone\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is a novel written by \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    J.K. Rowling\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('Apple is looking at buying a U.K startup for $6 billions')\n",
        "for ent in doc.ents:\n",
        "  print(ent.text+\" - \" +ent.label_+\" - \"+str(spacy.explain(ent.label_)))"
      ],
      "metadata": {
        "id": "JPDYm0mQgi0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feeb777b-5e0d-4a33-f3eb-d29809f20290"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple - ORG - Companies, agencies, institutions, etc.\n",
            "U.K - ORG - Companies, agencies, institutions, etc.\n",
            "$6 billions - MONEY - Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what are noun chunks\n",
        "\n",
        "# Noun chunks are phrases in a sentence that consist of a noun and any words that modify it, such as adjectives or determiners. They are a useful way to identify and extract the key information in a sentence, and can be thought of as the \"building blocks\" of natural language.\n",
        "\n",
        "# In the spaCy module, noun chunks can be identified using the noun_chunks attribute of a Doc object. This attribute returns a generator that yields Span objects representing the noun chunks in the document.\n",
        "\n",
        "# For example, consider the sentence \"The big brown dog chased the small white cat.\" The noun chunks in this sentence are \"The big brown dog\" and \"the small white cat\". These noun chunks can be extracted using the following code in spaCy:\n",
        "\n",
        "\n",
        "# import spacy\n",
        "\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "# doc = nlp(\"The big brown dog chased the small white cat.\")\n",
        "# for chunk in doc.noun_chunks:\n",
        "#     print(chunk.text)\n",
        "\n",
        "\n",
        "# This code will output:\n",
        "\n",
        "# The big brown dog\n",
        "# the small white cat\n",
        "\n",
        "\n",
        "\n",
        "# Noun chunks can be useful for various natural language processing tasks, such as information extraction, summarization, and sentiment analysis.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ivueuBqvhx95"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('the big brown dog chased the small white cat.')\n",
        "for chunk in doc.noun_chunks:\n",
        "  print(chunk.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7IFfYoFjSiW",
        "outputId": "1e3f73e8-cfda-4ee8-db68-1ec6ca1b6d64"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the big brown dog\n",
            "the small white cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EXAMPLES\n",
        "\n",
        "\n",
        "# The tall, dark-haired man in the suit walked into the room.\n",
        "# Noun chunks: \"The tall, dark-haired man\", \"the suit\", \"the room\".\n",
        "\n",
        "# The delicious, warm chocolate chip cookies were waiting on the kitchen counter.\n",
        "# Noun chunks: \"The delicious, warm chocolate chip cookies\", \"the kitchen counter\".\n",
        "\n",
        "# My sister's new, expensive car was stolen from the parking lot.\n",
        "# Noun chunks: \"My sister's new, expensive car\", \"the parking lot\".\n",
        "\n",
        "# The old, wooden chest in the attic was filled with treasure.\n",
        "# Noun chunks: \"The old, wooden chest\", \"the attic\", \"treasure\".\n",
        "\n",
        "# The large, intimidating dog barked loudly at the mailman.\n",
        "# Noun chunks: \"The large, intimidating dog\", \"the mailman\".\n"
      ],
      "metadata": {
        "id": "3jyMkbDyjkac"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "Pn1zZOj7j0qA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #2types \n",
        " #porter stemmer\n",
        " #snow ball stemmer"
      ],
      "metadata": {
        "id": "5-5JKPlZ7zCA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "id": "_Yd0H0gK8CUZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_stem=PorterStemmer()"
      ],
      "metadata": {
        "id": "28hx6-U58LK6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words=['run','runner','running','runs','easily','fairly']\n",
        "for i in words:\n",
        "  print(i+'----------------->'+p_stem.stem(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVAT9-rO8QMi",
        "outputId": "855e7ffd-13d8-48a2-a7e7-732560a84b67"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run----------------->run\n",
            "runner----------------->runner\n",
            "running----------------->run\n",
            "runs----------------->run\n",
            "easily----------------->easili\n",
            "fairly----------------->fairli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the disadvantage in porterstemmer is its stems differently which doesn't exists in dictionary"
      ],
      "metadata": {
        "id": "K2xPca-z8mLI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#so overcome this we are using Snowball Stemmer. It offers a slight improvement over the original Porter Stemmer, both in logic and speed"
      ],
      "metadata": {
        "id": "kLfu64KC87H_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "QAMEVpq-9Du0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_stemmer=SnowballStemmer(language='english')"
      ],
      "metadata": {
        "id": "wiJZWjoHDcvI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words=['run','runner','running','runs','easily','fairly']\n",
        "for i in words:\n",
        "  print(i+'-------------------->'+s_stemmer.stem(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oGgjh2zETBp",
        "outputId": "e8ab95e0-dcf9-4a57-985d-a6b9938d67b6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run-------------------->run\n",
            "runner-------------------->runner\n",
            "running-------------------->run\n",
            "runs-------------------->run\n",
            "easily-------------------->easili\n",
            "fairly-------------------->fair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word=['consolingly']\n",
        "print('porter stemmer ------>'+p_stem.stem(word[0]))\n",
        "print('snowball stemmer ------->'+s_stemmer.stem(word[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALdhvnIUFt1M",
        "outputId": "b51ebabc-0412-410e-c54e-dad4113f4b6b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "porter stemmer ------>consolingli\n",
            "snowball stemmer ------->consol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s='I am doing well. what about you guys!!'\n",
        "for i in s.split():\n",
        "  print(i+'-------->'+p_stem.stem(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgvBHjmXJWRY",
        "outputId": "86547c8b-9034-4aa7-8852-def96a7ece1f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I-------->i\n",
            "am-------->am\n",
            "doing-------->do\n",
            "well.-------->well.\n",
            "what-------->what\n",
            "about-------->about\n",
            "you-------->you\n",
            "guys!!-------->guys!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in s.split():\n",
        "  print(i+'---------->'+s_stemmer.stem(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3Np5CdjKxgh",
        "outputId": "4ee7d07b-796a-45ad-fbb5-e7c0604b1183"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I---------->i\n",
            "am---------->am\n",
            "doing---------->do\n",
            "well.---------->well.\n",
            "what---------->what\n",
            "about---------->about\n",
            "you---------->you\n",
            "guys!!---------->guys!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization"
      ],
      "metadata": {
        "id": "Nke9pH1VK6q1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what is lemmatization\n",
        "# Lemmatization is the process of reducing a word to its base or root form, which is known as the lemma. The lemma is the canonical form of a word, and it represents the word's dictionary form. For example, the lemma of the word \"running\" is \"run\", the lemma of \"am, is, are\" is \"be\".\n",
        "\n",
        "# Lemmatization is an important technique in natural language processing, and it is used to standardize words so that they can be analyzed more easily. It helps to reduce the number of forms a word can take, which is important in tasks such as text classification, information retrieval, and machine translation.\n",
        "\n",
        "# Lemmatization is often used in combination with part-of-speech (POS) tagging, which is the process of identifying the part of speech of each word in a sentence. This is because the lemma of a word can depend on its part of speech. For example, the lemma of the word \"good\" is \"good\" when used as an adjective (e.g., \"a good book\"), but it is \"well\" when used as an adverb (e.g., \"he speaks English well\")."
      ],
      "metadata": {
        "id": "psZqIzjeLEpA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what is the difference between lemmatization and stemming\n",
        "# Both lemmatization and stemming are techniques used to reduce words to their base or root form, but they differ in the way they achieve this goal.\n",
        "\n",
        "# Stemming is a process of removing prefixes and suffixes from words to obtain their root form, which is called a stem. The stem may not necessarily be a word by itself, but it can still convey the general meaning of the original word. For example, the stem of the word \"jumping\" is \"jump\", and the stem of the word \"running\" is \"run\". Stemming is a simpler and faster process than lemmatization, but it may not always produce the correct root form.\n",
        "\n",
        "# Lemmatization, on the other hand, is a more sophisticated process that involves analyzing the structure of words based on their context and morphology to determine their root form, which is called a lemma. Unlike stemming, lemmatization produces an actual word that is present in a language's dictionary. For example, the lemma of the word \"jumping\" is \"jump\", and the lemma of the word \"running\" is also \"run\". Lemmatization is more accurate than stemming, but it is also more computationally intensive and may be slower.\n",
        "\n",
        "# In summary, stemming is a simpler and faster method of reducing words to their root form, while lemmatization is a more accurate but computationally more expensive process that produces an actual word. The choice between the two techniques depends on the specific task and the level of accuracy required.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RHyEWRIeMCiJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('I am a runner I am running day and also and i ran today, i will also run tommorow')\n",
        "for token in doc:\n",
        "  print(token.text+'\\t'+token.pos_+'\\t'+token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU0w6NlmMLxF",
        "outputId": "9497172c-b6da-4048-ebcd-e28ecb3afd62"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\tPRON\tI\n",
            "am\tAUX\tbe\n",
            "a\tDET\ta\n",
            "runner\tNOUN\trunner\n",
            "I\tPRON\tI\n",
            "am\tAUX\tbe\n",
            "running\tVERB\trun\n",
            "day\tNOUN\tday\n",
            "and\tCCONJ\tand\n",
            "also\tADV\talso\n",
            "and\tCCONJ\tand\n",
            "i\tPRON\tI\n",
            "ran\tVERB\trun\n",
            "today\tNOUN\ttoday\n",
            ",\tPUNCT\t,\n",
            "i\tPRON\tI\n",
            "will\tAUX\twill\n",
            "also\tADV\talso\n",
            "run\tVERB\trun\n",
            "tommorow\tNOUN\ttommorow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lemma_show(text):\n",
        "  for token in text:\n",
        "    print(f'{token.text:{12}} {token.pos_:{8}} {token.lemma:<{22}} {token.lemma_}')"
      ],
      "metadata": {
        "id": "NupOC_lhSGOc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('I saw nine mice today')\n",
        "lemma_show(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R6Ow1EkSk__",
        "outputId": "8ef92cc4-8186-4a09-befd-0ac01cfc1f3f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I            PRON     4690420944186131903    I\n",
            "saw          VERB     11925638236994514241   see\n",
            "nine         NUM      17718451046594752029   nine\n",
            "mice         NOUN     1384165645700560590    mouse\n",
            "today        NOUN     11042482332948150395   today\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# examples\n",
        "\n",
        "# Word: \"dogs\"\n",
        "# Lemma: \"dog\"\n",
        "\n",
        "# Word: \"ran\"\n",
        "# Lemma: \"run\"\n",
        "\n",
        "# Word: \"am\"\n",
        "# Lemma: \"be\"\n",
        "\n",
        "# Word: \"better\"\n",
        "# Lemma: \"good\"\n",
        "\n",
        "# Word: \"went\"\n",
        "# Lemma: \"go\"\n",
        "\n",
        "# Word: \"went\"\n",
        "# Lemma: \"go\"\n",
        "\n",
        "# Word: \"wolves\"\n",
        "# Lemma: \"wolf\"\n",
        "\n",
        "# Word: \"feet\"\n",
        "# Lemma: \"foot\"\n",
        "\n",
        "# Word: \"geese\"\n",
        "# Lemma: \"goose\"\n",
        "\n",
        "# Word: \"playing\"\n",
        "# Lemma: \"play\""
      ],
      "metadata": {
        "id": "rZ3aQvTlTBXV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(\"That's an enormous automobile\")\n",
        "lemma_show(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o5DwgrCTSjy",
        "outputId": "2fd472b6-f42d-4ba5-d71a-7d1b96c372c8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That         PRON     4380130941430378203    that\n",
            "'s           AUX      10382539506755952630   be\n",
            "an           DET      15099054000809333061   an\n",
            "enormous     ADJ      17917224542039855524   enormous\n",
            "automobile   NOUN     7211811266693931283    automobile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stops words\n",
        "# words like \"a\" and \"the\" appear so frequently that they dont;t require tagging  as throughly as nouns, verbs and modifiers. We call these stop words, and they can be filtered from the text to be processed spacy holds a built-in list of some 305 English stop words"
      ],
      "metadata": {
        "id": "MC9QbiDHT3UN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what are stop words\n",
        "\n",
        "# Stop words are common words that are often removed from texts during preprocessing, as they are considered to be uninformative or irrelevant for the analysis or classification task at hand. Stop words are typically the most common words in a language, such as \"the\", \"and\", \"of\", \"to\", \"in\", \"a\", \"an\", \"is\", \"are\", \"for\", \"that\", \"with\", \"on\", \"at\", \"by\", \"from\", \"as\", \"it\", \"its\", \"be\", \"been\", \"was\", \"were\", \"will\", \"would\", \"have\", \"has\", \"had\", \"can\", \"could\", \"should\", \"shall\", \"may\", \"might\", \"must\", etc.\n",
        "\n",
        "# Removing stop words can help to improve the efficiency of text processing by reducing the number of words that need to be analyzed, and can also improve the accuracy of some text analysis tasks by removing irrelevant information. However, in some cases, stop words may be important for the analysis, especially for tasks such as sentiment analysis, where the meaning of a sentence can be heavily influenced by the presence or absence of certain stop words.\n",
        "\n",
        "# It is worth noting that the list of stop words may vary depending on the specific task or application, as well as the language or dialect being analyzed. Therefore, it is common to create custom lists of stop words for a particular project or use case."
      ],
      "metadata": {
        "id": "65c4eSfTUhRl"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w-Npq44U29m",
        "outputId": "3b031815-d91a-4199-fba0-fe640a3d6852"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'used', 'can', 'meanwhile', 'someone', 'one', 'any', 'show', 'formerly', 'onto', 'over', 'next', 'it', 'their', 'front', 'hereby', 'whereafter', 'thereupon', 'yours', 'itself', 'noone', 'everything', 'amount', 'upon', 'often', 'a', 'being', 'get', 'give', 'whereupon', 'him', 'own', 'whence', \"'ve\", \"'d\", 'are', 'she', 'these', '’ll', 'hereupon', 'them', 'whoever', 'though', \"'re\", 'least', 'nowhere', 'seem', 'mine', 'that', 'anyway', 'were', 'your', 'somehow', 'toward', 'sixty', 'amongst', 'so', 'had', 'keep', 'thereafter', 'beyond', 'within', 'when', '‘ll', 'below', 'by', 'he', 'after', 'is', 'call', 'top', 'six', '’d', 'fifteen', 'becoming', 'latterly', 'afterwards', 'anyone', 'been', 'hers', 'eleven', 'out', 'most', 'both', '‘m', 'her', 'seems', 'across', 'beforehand', 'again', 'ca', 'in', 'such', '’re', 'nobody', 'rather', 'through', 'between', 'more', 'sometimes', 'about', 'almost', 'take', 'from', 'whatever', '‘re', 'ever', 'towards', 'seeming', 'third', 'those', 'before', 'ours', 'who', 'whose', 'several', 'sometime', 'empty', 'various', 'whole', 'anyhow', 'to', 'alone', 'n‘t', 'we', 'thru', 'into', 'whither', 'name', 'as', 'go', 'they', 'ourselves', 'less', 'while', 'seemed', 'there', 'hundred', 'also', 'doing', 'themselves', 'or', 'yourself', 'other', 'am', 'mostly', 'which', 'its', 'never', 'put', 'except', 'still', \"'s\", 'if', 'no', 'than', 'twenty', 'some', 'now', 'with', 'thereby', 'moreover', 'quite', 'elsewhere', 'n’t', 'without', 'whereby', '’ve', 'among', 'first', 'should', 'could', 'everywhere', 'please', 'becomes', 'else', 'be', 'something', 'therefore', 'besides', 'indeed', 'around', 'three', 'may', 'last', 'say', 'since', 'only', 'whereas', 'up', 'eight', 'himself', 'here', 'the', 'two', 'each', 'i', 'do', 'well', \"'ll\", 'latter', 'down', 'once', 'thence', 'really', 'off', 'side', 'full', 'hence', 'yet', 'cannot', 'twelve', 'an', 'unless', 'forty', 'for', 'this', 'whenever', 'back', 're', 'namely', 'others', 'nothing', 'anywhere', 'might', 'therein', 'me', 'against', 'fifty', 'our', 'then', 'five', 'another', 'where', 'everyone', 'under', 'why', '’m', 'made', 'former', 'together', 'ten', 'wherever', 'per', 'his', 'much', '‘ve', 'on', 'but', 'my', 'serious', 'how', 'however', 'has', 'all', 'bottom', 'further', 'must', 'nor', 'wherein', 'move', 'thus', 'during', 'not', 'otherwise', 'four', 'you', 'nevertheless', 'herself', 'anything', 'throughout', 'part', 'somewhere', 'via', 'of', 'same', 'herein', 'did', 'beside', 'every', 'enough', 'too', 'at', 'nine', 'see', 'became', 'make', 'either', 'was', 'although', 'using', 'because', 'done', 'hereafter', 'due', 'even', 'perhaps', 'what', 'above', 'behind', 'very', 'become', '‘d', 'none', 'would', 'already', 'neither', 'does', 'have', '‘s', 'whom', 'us', '’s', 'and', 'along', 'regarding', 'until', 'yourselves', \"'m\", 'whether', \"n't\", 'few', 'just', 'always', 'many', 'will', 'myself'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP02Q3UaVub_",
        "outputId": "da12a311-2fd4-4edb-9398-2e304a9deab4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['first'].is_stop  #it checks whether it is stop_word or not"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtcq1G7GV7f8",
        "outputId": "59a600cd-8ec8-470b-a3d0-4f6f7b49ff36"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['Gopikanth'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m080mtyDWCUV",
        "outputId": "79de92ab-c925-41e5-fc82-1a78b7fd00b2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a stop word to the vocabulary\n",
        "# if any word is repeating many times in our text such that our ml algorithm may got deviate and scores less score "
      ],
      "metadata": {
        "id": "jTF4v73ZWJ2w"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# why adding a stop word to the vocabulary\n",
        "\n",
        "# Adding a stop word to the vocabulary can be done for a few different reasons:\n",
        "\n",
        "# Importance: Sometimes a word that is normally considered a stop word may be important in the context of a specific task or analysis. For example, in sentiment analysis, the word \"not\" is often considered a stop word, but it can be crucial for understanding the sentiment of a sentence (e.g., \"I am not happy\" vs. \"I am happy\"). In such cases, adding the word \"not\" to the stop word list could negatively impact the accuracy of the analysis, so it may be beneficial to exclude it.\n",
        "\n",
        "# Filtering: Stop words are often used to filter out words that are common and uninformative. However, in some cases, certain words may be considered uninformative in one context but informative in another. For example, in a study of legal documents, words like \"law\" and \"regulation\" might be considered stop words in other contexts, but are important for understanding the content of legal documents. In this case, these words may be added to the vocabulary to ensure that they are not removed from the analysis.\n",
        "\n",
        "# Consistency: Depending on the tool or library being used, the list of stop words may vary. By adding a specific stop word to the vocabulary, you can ensure that it is consistently treated as a stop word throughout the analysis. This can help to avoid inconsistencies in the results and make it easier to interpret the output.\n",
        "\n",
        "# In general, adding a stop word to the vocabulary should be done thoughtfully and with a clear understanding of the implications for the analysis. It is important to consider the specific task or application, as well as the language and dialect being analyzed, when deciding which words to include or exclude from the stop word list."
      ],
      "metadata": {
        "id": "FEl5az7GXLW2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.Defaults.stop_words.add('Gopikanth')\n",
        "nlp.vocab['Gopikanth'].is_stop=True"
      ],
      "metadata": {
        "id": "fsZ3XKTCcSeo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['Gopikanth'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyGHIRpPcZbZ",
        "outputId": "4da799c3-f11a-4609-ed22-4f79faaf3682"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgOY3-Ceclwf",
        "outputId": "b3784f62-2a87-4f96-afd0-8e333b42de88"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "327"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing a stop word from thye vocabulary\n",
        "# Removing a stop word from the vocabulary can be done for a few different reasons:\n",
        "\n",
        "# Relevance: In some cases, a word that is normally considered a stop word may be relevant to the task or analysis at hand. For example, in a study of social media posts, words like \"lol\" or \"omg\" might be important for understanding the tone or sentiment of the post. In such cases, removing these words from the stop word list could help to improve the accuracy of the analysis.\n",
        "\n",
        "# Precision: Depending on the specific analysis, removing certain stop words can help to increase the precision of the results. For example, if you are using a bag-of-words model to classify text, removing stop words can reduce the dimensionality of the feature space and improve the accuracy of the classification.\n",
        "\n",
        "# Context: Stop words are often used to remove words that are common and uninformative, but the list of stop words may not be appropriate for all contexts. For example, the stop word \"not\" may be important in some contexts, such as sentiment analysis, but not in others. By removing certain stop words, you can tailor the analysis to the specific context and improve the relevance of the results.\n",
        "\n",
        "# It's important to note that removing a stop word should be done thoughtfully and with a clear understanding of the implications for the analysis. Removing stop words can sometimes lead to overfitting or loss of information, so it's important to carefully consider the trade-offs between precision, recall, and relevance when deciding which words to remove from the stop word list.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bN0TOCLAcudt"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.Defaults.stop_words.remove('Gopikanth')\n",
        "nlp.vocab['Gopikanth'].is_stop=False"
      ],
      "metadata": {
        "id": "6tBynRDLdXsx"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['Gopikanth'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BsDuojzd2oS",
        "outputId": "99896296-9792-44c3-9d00-3a90da926821"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyaVj78Ed_C-",
        "outputId": "8c974b71-5d7f-4175-953f-ddf0f131350c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.Defaults.stop_words.remove('only')\n",
        "nlp.vocab['only'].is_stop=False"
      ],
      "metadata": {
        "id": "5N8ZbS5HeCxD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['only'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxfotT3keSB_",
        "outputId": "fb13fb3d-d7a1-4db4-be6c-47a12c193680"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPzjMguweVd6",
        "outputId": "d8ab4043-cadf-41c2-ca24-a447967dadab"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "325"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.Defaults.stop_words.add('only')\n",
        "nlp.vocab['only'].is_stop=True"
      ],
      "metadata": {
        "id": "aAcLEtVieaY4"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['only'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7bEbHH_eg-d",
        "outputId": "fb9b6fdd-46cc-4e7a-8bb7-a21e824824f3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(nlp.Defaults.stop_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA3WWH2ceiWa",
        "outputId": "c25d0d7d-803d-4270-daf3-6915af2b981a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", 'a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'both', 'bottom', 'but', 'by', 'ca', 'call', 'can', 'cannot', 'could', 'did', 'do', 'does', 'doing', 'done', 'down', 'due', 'during', 'each', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', 'fifteen', 'fifty', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had', 'has', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'if', 'in', 'indeed', 'into', 'is', 'it', 'its', 'itself', 'just', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'made', 'make', 'many', 'may', 'me', 'meanwhile', 'might', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'my', 'myself', \"n't\", 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'n‘t', 'n’t', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'quite', 'rather', 're', 'really', 'regarding', 'same', 'say', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'six', 'sixty', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', 'under', 'unless', 'until', 'up', 'upon', 'us', 'used', 'using', 'various', 'very', 'via', 'was', 'we', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves', '‘d', '‘ll', '‘m', '‘re', '‘s', '‘ve', '’d', '’ll', '’m', '’re', '’s', '’ve']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# natural language toolkit"
      ],
      "metadata": {
        "id": "-tkAf43xi5TM"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPZZ-AeCjEw4",
        "outputId": "490a6803-f972-4983-ae79-40f6f0177f13"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words=stopwords.words('english')\n",
        "type(stop_words)\n",
        "len(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWsd3gtKjrss",
        "outputId": "50131838-3c78-42e7-c73f-7919cb3aaa8c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stops_words in scikit-learn"
      ],
      "metadata": {
        "id": "6BoXUJS_kmh6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction import text"
      ],
      "metadata": {
        "id": "Qna0qhKfl-nO"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words=text.ENGLISH_STOP_WORDS\n",
        "len(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTdk7infqq8d",
        "outputId": "2ad23ed1-85e0-435b-ff68-9f6e2525ebfc"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "318"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(list(stop_words)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6fmt8h7urCU",
        "outputId": "1b70db6e-22a1-4d79-ef0b-9ea74c32dea6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'con', 'could', 'couldnt', 'cry', 'de', 'describe', 'detail', 'do', 'done', 'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'interest', 'into', 'is', 'it', 'its', 'itself', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 'same', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system', 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOdxBTYfuxnw",
        "outputId": "97e1c1bd-c3f7-47cd-be2f-7aa615be122c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "frozenset"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary matching"
      ],
      "metadata": {
        "id": "n_R7bKxRyeuv"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rule base matching"
      ],
      "metadata": {
        "id": "v1-i3l512CGH"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from thinc.shims import pytorch\n",
        "# spacy\n",
        "# scikit-learn\n",
        "# nltk\n",
        "# hugging face\n",
        "# tensorflow\n",
        "# pytorch\n",
        "# hugging face\n",
        "# gensim"
      ],
      "metadata": {
        "id": "i9ZWffsB2UDx"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apis\n",
        "\n",
        "# Fasttext\n",
        "# Tensorflow Hub\n",
        "# GPT3"
      ],
      "metadata": {
        "id": "igVS_AK77I_9"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what is rule based matching\n",
        "# Rule-based matching is a technique used in natural language processing (NLP) to identify and extract specific patterns or phrases in text based on a set of pre-defined rules. These rules can be simple or complex and can involve matching on various criteria such as part of speech, entities, and syntactic dependencies.\n",
        "\n",
        "# In rule-based matching, a set of rules or patterns is defined using regular expressions, grammars, or other linguistic tools. These rules are then applied to text to identify instances that match the specified patterns. This can be useful in a variety of applications, such as information extraction, sentiment analysis, and chatbots.\n",
        "\n",
        "# For example, let's say we want to extract all the dates mentioned in a text. We could define a rule that matches any sequence of words that looks like a date, such as \"January 1, 2022\" or \"02/14/2023\". We could also define rules that match other date-related phrases, such as \"next week\" or \"last month\". By applying these rules to the text, we can extract all the relevant date information.\n",
        "\n",
        "# Rule-based matching can be a powerful technique for certain types of NLP tasks, but it does have limitations. It requires a significant amount of upfront work to define the rules and patterns, and it may not be effective for more complex tasks where the patterns are difficult to define. Additionally, it may be less flexible than other approaches such as machine learning, which can adapt to new patterns and data."
      ],
      "metadata": {
        "id": "SSQqHzsE72Tb"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# application : otp will resads directly in some apps that is the rule based application"
      ],
      "metadata": {
        "id": "9u6dms-8BL9c"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher"
      ],
      "metadata": {
        "id": "NUha6f7TBcXY"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matcher=Matcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "W-IXGG5NBwr2"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The next step is to define the patterns that will be used to filter similar phrases. suppose\n",
        "# we want to find the phrases 'quick-brown-fox', 'quick brown fox'\n",
        "# or 'quick brownfox'.To do so we need to create the following four patterns:"
      ],
      "metadata": {
        "id": "BUJyYQpXB7mi"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9INaWt_JGvt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1=[{'LOWER':'quickbrownfox'}]\n",
        "p2=[{'LOWER':'quick'}, {'IS_PUNCT':True},{'LOWER':'brown'},{'IS_PUNCT':True},{'LOWER':'fox'}]\n",
        "p3=[{'LOWER':'quick'},{'LOWER':'brown'},{'LOWER':'fox'}]\n",
        "p4=[{'LOWER':'quick'},{'LOWER':'brownfox'}]"
      ],
      "metadata": {
        "id": "540LnZwOCgb5"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matcher.add('QBF', None, p1,p2,p3,p4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "FtGFmbHqG9-M",
        "outputId": "57f2fe15-0c04-4d5c-dca6-98edf581e540"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-0349f49dff0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'QBF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/matcher/matcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.matcher.Matcher.add\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: add() takes exactly 2 positional arguments (6 given)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tagging"
      ],
      "metadata": {
        "id": "4yK3HYPgHHwB"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('The quick brown fox jumped over dog\\'s back')\n",
        "for token in doc:\n",
        "  print(f'{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {str(spacy.explain(token.tag_))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFS4LYi0IVdD",
        "outputId": "8991c869-64f4-4bd2-f795-1a74aa263fd0"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The        DET        DT         determiner\n",
            "quick      ADJ        JJ         adjective (English), other noun-modifier (Chinese)\n",
            "brown      ADJ        JJ         adjective (English), other noun-modifier (Chinese)\n",
            "fox        NOUN       NN         noun, singular or mass\n",
            "jumped     VERB       VBD        verb, past tense\n",
            "over       ADP        IN         conjunction, subordinating or preposition\n",
            "dog        NOUN       NN         noun, singular or mass\n",
            "'s         PART       POS        possessive ending\n",
            "back       ADV        RB         adverb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting POS tags"
      ],
      "metadata": {
        "id": "gWY2wg6PI2Qd"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_counts=doc.count_by(spacy.attrs.POS)"
      ],
      "metadata": {
        "id": "02YXFpFkJY-B"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "597B3S_2LurW",
        "outputId": "ef5ede70-8b91-48be-8758-a441a599f811"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{90: 1, 84: 2, 92: 2, 100: 1, 85: 1, 94: 1, 86: 1}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in pos_counts:\n",
        "  j=doc.vocab[i].text\n",
        "  print(j,str(spacy.explain(j)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3PMQMeuLwOO",
        "outputId": "e3914b94-954b-475f-f538-d18396ec925c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DET determiner\n",
            "ADJ adjective\n",
            "NOUN noun\n",
            "VERB verb\n",
            "ADP adposition\n",
            "PART particle\n",
            "ADV adverb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Named Entity Recognition"
      ],
      "metadata": {
        "id": "huqytizWMIIt"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('Apple is looking at U.K. startup for buying at $6 millions')\n",
        "for token in doc.ents:\n",
        "  print(token.text+'----->'+token.label_+'------>'+str(spacy.explain(token.label_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMLH8mC-vs_E",
        "outputId": "d8cd5a4a-27c1-4e47-820f-b1eb092aa5b3"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple----->ORG------>Companies, agencies, institutions, etc.\n",
            "U.K.----->GPE------>Countries, cities, states\n",
            "$6 millions----->MONEY------>Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_entities(doc):\n",
        "  if doc.ents:\n",
        "    for ent in doc.ents:\n",
        "      print(ent.text+'------->'+ent.label_+'------>'+str(spacy.explain(ent.label_)))\n",
        "  else:\n",
        "    print('no entities found')"
      ],
      "metadata": {
        "id": "G35BySP0wV1Q"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_entities(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7iiR-OFxJRz",
        "outputId": "0b5ee075-a59a-4e6b-f46f-6e65aaca6cb0"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple------->ORG------>Companies, agencies, institutions, etc.\n",
            "U.K.------->GPE------>Countries, cities, states\n",
            "$6 millions------->MONEY------>Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('May I go to washington, DC next May to see the Washington Monument')"
      ],
      "metadata": {
        "id": "pMLIA59WxNxC"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_entities(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuujWLAlxa8J",
        "outputId": "ca0bc27d-ca0b-4001-dca4-f68f299ace88"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "washington------->GPE------>Countries, cities, states\n",
            "DC------->GPE------>Countries, cities, states\n",
            "next May------->DATE------>Absolute or relative dates or periods\n",
            "the Washington Monument------->ORG------>Companies, agencies, institutions, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ent.text : The original entity text\n",
        "# ent.label : The entity type's hash value \n",
        "# ent.label_: The entity type's string discription\n",
        "# ent.start : The token span's start index position in the Doc\n",
        "# ent.end : The token span's stop index position in the Doc"
      ],
      "metadata": {
        "id": "axGAyMrDxeYb"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "  print(ent.text,ent.start,ent.start_char,ent.end,ent.end_char,ent.label,ent.label_,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CSF-D8pyE0h",
        "outputId": "37ab0591-3c07-4b8d-b663-8beea1803c7b"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "washington 4 12 5 22 384 GPE\n",
            "DC 6 24 7 26 384 GPE\n",
            "next May 7 27 9 35 391 DATE\n",
            "the Washington Monument 11 43 14 66 383 ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a named entity to a span"
      ],
      "metadata": {
        "id": "rfFVSQ9RyhKv"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('welcome to my socialbook')\n",
        "show_entities(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMVZqR4czn5c",
        "outputId": "0b82963c-a84a-4735-cec0-bdf6947dc98e"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no entities found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ1BAY2lzx83",
        "outputId": "5f8b66b0-6b0b-4285-d5cd-dde60725fed0"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "socialbook"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import Span\n",
        "org=doc.vocab.strings['ORG']"
      ],
      "metadata": {
        "id": "Nelv6FsJ0CyN"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "org"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2AKws6u0Tut",
        "outputId": "01bd4d10-f343-4107-f26d-b3a192130536"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "383"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_ent=Span(doc,3,4,label=org)"
      ],
      "metadata": {
        "id": "Dm_dGCSN0Uii"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Span(doc,start_index,end_index,label=org)"
      ],
      "metadata": {
        "id": "VH14frz80ZSg"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_ent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJu38IA60p3A",
        "outputId": "4e862589-b28b-4eb7-f42e-38c00b174f01"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "socialbook"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc.ents=list(doc.ents)+[new_ent]"
      ],
      "metadata": {
        "id": "WJoP1APd0tpS"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_entities(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM9wPSBX00rb",
        "outputId": "4af6df5a-2575-431e-95b1-07cf8f1b4298"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "socialbook------->ORG------>Companies, agencies, institutions, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc,style='ent',jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Y1afJZMd02m4",
        "outputId": "b4a6c131-e1e7-479b-f6b4-7992b9af0c9d"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">welcome to my \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    socialbook\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1=nlp(\"Apple is planning to release a new iPhone next month. Elon Musk, the CEO of Tesla, announced that they will build a new factory in Germany. The United Nations held a summit to discuss climate change and sustainable development. Shakespeare was born in Stratford-upon-Avon on April 23, 1564. Harry Potter and the Philosopher's Stone is a novel written by J.K. Rowling.\")\n",
        "for ent in doc1.ents:\n",
        "  print(ent.text+\" - \" +ent.label_+\" - \"+str(spacy.explain(ent.label_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHs2nNrs0_iE",
        "outputId": "8495d69d-4643-43be-96c9-29bfb0727859"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple - ORG - Companies, agencies, institutions, etc.\n",
            "iPhone - ORG - Companies, agencies, institutions, etc.\n",
            "next month - DATE - Absolute or relative dates or periods\n",
            "Elon Musk - PERSON - People, including fictional\n",
            "Tesla - ORG - Companies, agencies, institutions, etc.\n",
            "Germany - GPE - Countries, cities, states\n",
            "The United Nations - ORG - Companies, agencies, institutions, etc.\n",
            "Shakespeare - PERSON - People, including fictional\n",
            "Stratford - ORG - Companies, agencies, institutions, etc.\n",
            "April 23, 1564 - DATE - Absolute or relative dates or periods\n",
            "Harry Potter - PERSON - People, including fictional\n",
            "the Philosopher's Stone - ORG - Companies, agencies, institutions, etc.\n",
            "J.K. Rowling - PERSON - People, including fictional\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc1,style='ent',jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "PwcVY3SS1QpK",
        "outputId": "b9525aef-b8df-4606-dde1-5f5b68c59ab0"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is planning to release a new \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    iPhone\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    next month\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Elon Musk\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", the CEO of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tesla\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", announced that they will build a new factory in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Germany\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    The United Nations\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " held a summit to discuss climate change and sustainable development. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Shakespeare\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " was born in \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Stratford\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "-upon-Avon on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    April 23, 1564\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Harry Potter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the Philosopher's Stone\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is a novel written by \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    J.K. Rowling\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options={'ents':{'ORG','DATE'}}"
      ],
      "metadata": {
        "id": "-RMX7eHY1Yca"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc1,style='ent',jupyter=True,options=options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "hVM6BDfL1drn",
        "outputId": "3f10f37b-9e34-4b30-ba1d-ba5aeb4863da"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is planning to release a new \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    iPhone\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    next month\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". Elon Musk, the CEO of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tesla\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", announced that they will build a new factory in Germany. \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    The United Nations\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " held a summit to discuss climate change and sustainable development. Shakespeare was born in \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Stratford\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "-upon-Avon on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    April 23, 1564\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". Harry Potter and \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the Philosopher's Stone\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is a novel written by J.K. Rowling.</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can also chage the names of the above entities colors by using some parameters"
      ],
      "metadata": {
        "id": "XSqWln5X1jgw"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BAG OF WORDS"
      ],
      "metadata": {
        "id": "B0c7wnY617LO"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  what is bag of words\n",
        "\n",
        "\n",
        "# The \"bag of words\" (BoW) is a simple text representation technique used in natural language processing and information retrieval. It involves converting a piece of text into a collection (or \"bag\") of individual words, ignoring grammar and word order, and counting the frequency of each word in the text.\n",
        "\n",
        "# In other words, the BoW model represents a text document as a set of words without any consideration for the order in which they appear. The order is not taken into account, only the frequency of each word is recorded. This method can be useful for text classification, sentiment analysis, and information retrieval.\n",
        "\n",
        "# For example, given the sentence \"The cat in the hat\", the corresponding BoW representation would be:\n",
        "# {\"the\": 2, \"cat\": 1, \"in\": 1, \"hat\": 1}\n",
        "\n",
        "# As you can see, the BoW model represents the sentence as a collection of words with their corresponding frequencies."
      ],
      "metadata": {
        "id": "Z5Y0nbGX2BNb"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sure! Here's an example of how the bag of words technique can be used:\n",
        "\n",
        "# Let's say we have a collection of three documents:\n",
        "\n",
        "# Document 1: \"The quick brown fox jumps over the lazy dog\"\n",
        "# Document 2: \"The lazy dog sleeps all day\"\n",
        "# Document 3: \"The quick brown fox and the lazy dog\"\n",
        "\n",
        "# To represent these documents using the bag of words model, we first create a vocabulary of all the unique words in the collection, ignoring stop words like \"the\", \"and\", and \"all\". In this case, the vocabulary would be:\n",
        "\n",
        "# Vocabulary: quick, brown, fox, jumps, over, lazy, dog, sleeps\n",
        "\n",
        "# Next, we count the frequency of each word in each document, and represent the documents as vectors of word frequencies:\n",
        "\n",
        "# Document 1: {quick: 1, brown: 1, fox: 1, jumps: 1, over: 1, lazy: 1, dog: 1, sleeps: 0}\n",
        "# Document 2: {quick: 0, brown: 0, fox: 0, jumps: 0, over: 0, lazy: 1, dog: 1, sleeps: 1}\n",
        "# Document 3: {quick: 1, brown: 1, fox: 1, jumps: 0, over: 0, lazy: 1, dog: 1, sleeps: 0}\n",
        "\n",
        "# As you can see, each document is represented as a vector of word frequencies, with the index of each element corresponding to the position of the word in the vocabulary. This allows us to compare and analyze the documents based on their word frequencies, without considering the order of the words."
      ],
      "metadata": {
        "id": "b3Bobc4E3dQ4"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count Vectorised\n",
        "# tf-Idf Vectorized : Term Frequency and Inverse Document Frequency"
      ],
      "metadata": {
        "id": "dk-5M_Kt3yKd"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count vectorization and tf-idf vectorization are two common methods used to convert text data into numerical vectors that can be used as input for machine learning algorithms.\n",
        "\n",
        "# Count vectorization simply counts the frequency of each word in a document and represents the document as a vector of these word frequencies. This is the basic bag of words representation we discussed earlier. For example, if we have a sentence \"The quick brown fox jumps over the lazy dog\", the corresponding count vector would be {the: 2, quick: 1, brown: 1, fox: 1, jumps: 1, over: 1, lazy: 1, dog: 1}. Count vectorization is a simple and effective method, but it does not account for the relative importance of words in a document.\n",
        "\n",
        "# TF-IDF vectorization (term frequency-inverse document frequency) is a method that takes into account both the frequency of a word in a document and the frequency of the word in the corpus (i.e., collection of documents). The idea behind TF-IDF is that words that appear frequently in a document but rarely in the corpus are more important in describing the content of the document. Conversely, words that appear frequently in the corpus but rarely in a document are less important.\n",
        "\n",
        "# To compute the TF-IDF score for each word in a document, we multiply the term frequency (TF) of the word (i.e., the frequency of the word in the document) by the inverse document frequency (IDF) of the word, which is a measure of how rare the word is in the corpus. The IDF of a word is computed as the logarithm of the total number of documents in the corpus divided by the number of documents that contain the word. The resulting TF-IDF score gives a measure of the importance of each word in the document.\n",
        "\n",
        "# Overall, TF-IDF vectorization can be a more effective way to represent text data than count vectorization, as it takes into account the relative importance of words in a document and the corpus."
      ],
      "metadata": {
        "id": "tqVKLg9y4q-f"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFZQ-8oZ4syT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}